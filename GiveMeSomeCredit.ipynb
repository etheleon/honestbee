{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Challenge : Give Me Some Credit\n",
    "\n",
    "\n",
    "<img src=\"https://kaggle2.blob.core.windows.net/competitions/kaggle/2551/logos/front_page.png\" style=\"width:200px;height:100px;\">\n",
    "\n",
    "Give Me Some Credit\n",
    "Improve on the state of the art in credit scoring by predicting the probability that somebody will experience financial distress in the next two years.\n",
    "\n",
    "Banks play a crucial role in market economies. They decide who can get finance and on what terms and can make or break investment decisions. For markets and society to function, individuals and companies need access to credit. \n",
    "\n",
    "Credit scoring algorithms, which make a guess at the probability of default, are the method banks use to determine whether or not a loan should be granted. This competition requires participants to improve on the state of the art in credit scoring, by predicting the probability that somebody will experience financial distress in the next two years.\n",
    "\n",
    "The goal of this competition is to build a model that borrowers can use to help make the best financial decisions.\n",
    "\n",
    "Historical data are provided on 250,000 borrowers and \n",
    "the prize pool is 5,000 \n",
    "\n",
    "* 3,000 for first, \n",
    "* 1,500 for second and \n",
    "* 500 for third.\n",
    "\n",
    "## Methods\n",
    "\n",
    "I'm going to implement a ensemble classifier using a couple of methods:\n",
    "\n",
    "* xgboost\n",
    "* Random Forest \n",
    "* SVM\n",
    "* PCA\n",
    "* Artificial Neural Networks\n",
    "\n",
    "## Scoring Metric: Area Under the Curve (AUC)\n",
    "\n",
    "Evaluation is done us the AUC or Receiver operating characteristic (ROC), sometimes also referred collectively as \n",
    " Area Under the Receiver Operating Characteristic curve.\n",
    " \n",
    "\n",
    "Y-axis is True Positive Rate (TPR) / Sensitivity\n",
    "X-axis is the False Positive Rate (FPR) / 1 - specificity\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Sensitivity_and_specificity.svg/700px-Sensitivity_and_specificity.svg.png\"  style=\"height:400px; width:200px\">\n",
    "<caption><center> **ROC AUC**</center></caption><br>\n",
    "\n",
    "TPR = True positives / Positives \n",
    "Positives = True Positives + False Negativs\n",
    "\n",
    "FPR = False Positives / Negatives\n",
    "Negatives = True Negatives + False Positives\n",
    "\n",
    "<img src=\"http://mchp-appserv.cpe.umanitoba.ca/concept/roc_gif_small.gif\">\n",
    "<caption><center> **Figure 1**</center></caption><br>\n",
    "\n",
    "Thus having a high AUC curve will be to have a high sensitivity while keeping the false positive rate low\n",
    "\n",
    "Besides AUC/ROC there's also log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"shell_port\": 35011,\n",
      "  \"iopub_port\": 33659,\n",
      "  \"stdin_port\": 54849,\n",
      "  \"control_port\": 34247,\n",
      "  \"hb_port\": 35099,\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"key\": \"01f2e6c5-3150a01e10667c1221c1d891\",\n",
      "  \"transport\": \"tcp\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"kernel_name\": \"\"\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-675dbf3b-12b5-4751-a915-fa846702971e.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "#now lets import the universe\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "#import rpy2\n",
    "#%load_ext rpy2.ipython\n",
    "# use R's ggplot to plot instead\n",
    "\n",
    "#machine learning\n",
    "## xgboost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "## sklearn\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion     #\n",
    "from sklearn_pandas import DataFrameMapper    #\n",
    "from sklearn_pandas import CategoricalImputer #\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Imputer\n",
    "#score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Custom class used for this analysis\n",
    "# Includes download dataset, submit prediction, load data (includes some preprocessing)\n",
    "from honest import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading to /data/examples/honestbee\n"
     ]
    }
   ],
   "source": [
    "#Downloads the dataset using Kaggle's API\n",
    "Utils.downloadData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data\n",
    "\n",
    "Below's the description of the input data:\n",
    "\n",
    "| Variable Name | Description | Type |\n",
    "| --- | --- | --- |\n",
    "| SeriousDlqin2yrs  | Person experienced 90 days past due delinquency or worse |  Y/N |\n",
    "| RevolvingUtilizationOfUnsecuredLines  | Total balance on credit cards and personal lines of credit except real estate and no installment debt like car loans divided by the sum of credit limits  | percentage | \n",
    "| age | Age of borrower in years  | integer |\n",
    "| NumberOfTime30-59DaysPastDueNotWorse  | Number of times borrower has been 30-59 days past due but no worse in the last 2 years. | integer |\n",
    "| DebtRatio | Monthly debt payments, alimony,living costs divided by monthy gross income | percentage |\n",
    "| MonthlyIncome | Monthly income  | real |\n",
    "| NumberOfOpenCreditLinesAndLoans | Number of Open loans (installment like car loan or mortgage) and Lines of credit (e.g. credit cards)  | integer |\n",
    "| NumberOfTimes90DaysLate | Number of times borrower has been 90 days or more past due. | integer |\n",
    "| NumberRealEstateLoansOrLines  | Number of mortgage and real estate loans including home equity lines of credit  | integer| \n",
    "| NumberOfTime60-89DaysPastDueNotWorse  | Number of times borrower has been 60-89 days past due but no worse in the last 2 years. | integer | \n",
    "| NumberOfDependents |  Number of dependents in family excluding themselves (spouse, children etc.) | integer | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis\n",
    "\n",
    "## 1. Class imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>defaulted</td>\n",
       "      <td>10026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clean</td>\n",
       "      <td>139974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class   value\n",
       "0  defaulted   10026\n",
       "1      clean  139974"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, testDF = Utils.loadData(preprocessed=False)\n",
    "defaulted = np.sum(y_train != 0) + np.sum(y_test != 0)\n",
    "clean = np.sum(y_train == 0) + np.sum(y_test == 0)\n",
    "\n",
    "classSep = pd.DataFrame({\n",
    "    \"class\":[\"defaulted\",\"clean\"],\n",
    "    \"value\":[defaulted, clean]\n",
    "}, index=[0,1])\n",
    "classSep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAFoCAIAAADxRFtOAAAACXBIWXMAAAsSAAALEgHS3X78AAAg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\ngg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i classSep -w 10 -h 5 -u in\n",
    "\n",
    "suppressPackageStartupMessages({\n",
    "    library(tidyverse)\n",
    "    library(cowplot)\n",
    "})\n",
    "\n",
    "suppressMessages({\n",
    "    p1 = ggplot(classSep, aes(class, value, fill=class))+ \n",
    "        geom_histogram(stat=\"identity\") +\n",
    "        geom_text(aes(y=value, label=value)) + \n",
    "        scale_fill_discrete(\"Default\", labels=c(\"Good\", \"Default\")) +\n",
    "        scale_y_log10() + ggtitle(\"Y-Log10 scale\")\n",
    "     p2 = ggplot(classSep, aes(class, value, fill=class))+ \n",
    "        geom_histogram(stat=\"identity\") +\n",
    "        geom_text(aes(y=value, label=value)) + \n",
    "        scale_fill_discrete(\"Default\", labels=c(\"Good\", \"Default\")) + ggtitle(\"Linear Y Scale\")\n",
    "    p = plot_grid(p1, p2, nrow=1) \n",
    "    print(p)\n",
    "        })   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R -i X_train \n",
    "\n",
    "suppressWarnings({ \n",
    "        library(tidyverse)\n",
    "        library(GGally)\n",
    "        ggpairs(X_train) %>% ggsave(filename=\"ggpairs.png\", w=30, h=30, dpi=300) \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./ggpairs.png\">\n",
    "<caption><center> **Figure 2**: Pairs plot</center></caption><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation:__ A lot of the colunmns do not follow a guassian distribution, lets do some log transformation on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R -i X_train \n",
    "\n",
    "suppressWarnings({ \n",
    "        library(tidyverse)\n",
    "        library(GGally)\n",
    "        X_train %>% select(-DebtRatio, -NumberOfTime30.59DaysPastDueNotWorse, -MonthlyIncome, \n",
    "                                    -NumberOfOpenCreditLinesAndLoans, -NumberOfTimes90DaysLate, \n",
    "                                    -NumberRealEstateLoansOrLines, -NumberOfTime60.89DaysPastDueNotWorse) %>% \n",
    "        ggpairs() %>%\n",
    "        ggsave(filename=\"ggpairslog.png\", w=30, h=30, dpi=300) \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"./ggpairslog.png\">\n",
    "<caption><center> **Figure 2**: Pairs plot</center></caption><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better now, lets try with the different classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model1: XGB\n",
    "\n",
    "XGB is an ensemble based classifier based on a generalised gradient boosting algorithm. Other packages do exist like lightGBM from microsoft. \n",
    "\n",
    "Usually the base classifier is a decision tree, where each tree is built sequentially after the one another, with the new predictor directly addresses the weaknesses in the previous models.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/dmlc/web-data/master/xgboost/model/twocart.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 120000 entries, 146722 to 11328\n",
      "Data columns (total 16 columns):\n",
      "RevolvingUtilizationOfUnsecuredLines        120000 non-null float64\n",
      "age                                         120000 non-null int64\n",
      "NumberOfTime30-59DaysPastDueNotWorse        120000 non-null int64\n",
      "DebtRatio                                   120000 non-null float64\n",
      "MonthlyIncome                               96284 non-null float64\n",
      "NumberOfOpenCreditLinesAndLoans             120000 non-null int64\n",
      "NumberOfTimes90DaysLate                     120000 non-null int64\n",
      "NumberRealEstateLoansOrLines                120000 non-null int64\n",
      "NumberOfTime60-89DaysPastDueNotWorse        120000 non-null int64\n",
      "NumberOfDependents                          116837 non-null float64\n",
      "NumberOfTime30-59DaysPastDueNotWorse-log    120000 non-null float64\n",
      "MonthlyIncome-log                           96284 non-null float64\n",
      "NumberOfOpenCreditLinesAndLoans-log         120000 non-null float64\n",
      "NumberOfTimes90DaysLate-log                 120000 non-null float64\n",
      "NumberRealEstateLoansOrLines-log            120000 non-null float64\n",
      "NumberOfTime60-89DaysPastDueNotWorse-log    120000 non-null float64\n",
      "dtypes: float64(10), int64(6)\n",
      "memory usage: 15.6 MB\n"
     ]
    }
   ],
   "source": [
    "#with log columns\n",
    "X_train, X_test, y_train, y_test, testDF = loadData(logTransform=True, \n",
    "                                                    impute=False, \n",
    "                                                    preprocessed=False)\n",
    "X_train.info()\n",
    "#There's still some rows with missing values, let us solve this by using an Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due the class imbalance we observed earlier, \n",
    "lets check if the splitting results in the same class imbalance we see in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06684166666666666, 0.06683333333333333)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "np.sum(y_train)/len(y_train), np.sum(y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets account for the missing data using the `Imputer` function by taking the median (median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.960728088766986"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = (y_train == 0).sum() / (1.0 * (y_train == 1).sum())\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Standardised sklearn pipeline with XGB\n",
    "# Create a boolean mask for categorical columns\n",
    "# Dont really need cause none of the columns are objects but lets just keep it \n",
    "categorical_feature_mask = X_train.dtypes == object\n",
    "\n",
    "# Get list of categorical column names\n",
    "categorical_columns = X_train.columns[categorical_feature_mask].tolist()\n",
    "\n",
    "# Get list of non-categorical column names\n",
    "non_categorical_columns = X_train.columns[~categorical_feature_mask].tolist()\n",
    "\n",
    "# Apply numeric imputer (using median/mean) both gives almost the same value\n",
    "# aka fill the NaNs\n",
    "numeric_imputation_mapper = DataFrameMapper(\n",
    "   [([numeric_feature], Imputer(strategy=\"median\")) for numeric_feature in non_categorical_columns],\n",
    "   input_df=True,\n",
    "   df_out=True\n",
    ")\n",
    "\n",
    "categorical_imputation_mapper = DataFrameMapper(\n",
    "    [(category_feature, Categorical()) for category_feature in categorical_columns],\n",
    "    input_df=True,\n",
    "    df_out=True\n",
    ")\n",
    "\n",
    "# Combine the numeric and categorical transformations\n",
    "numeric_categorical_union = FeatureUnion([\n",
    "    (\"num_mapper\", numeric_imputation_mapper),\n",
    "    (\"cat_mapper\", categorical_imputation_mapper)\n",
    "])\n",
    "\n",
    "\n",
    "# Create full pipeline\n",
    "pipeline = Pipeline([\n",
    "   (\"featureunion\", numeric_imputation_mapper),\n",
    "   (\"clf\", xgb.XGBClassifier(max_depth=10, \n",
    "                         scale_pos_weight=weights, \n",
    "                             gamma=20 #gamma is set high for class imbalance\n",
    "                            )) #class imbalance\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-fold AUC:  0.8535582293495284\n"
     ]
    }
   ],
   "source": [
    "# Print avg. AUC\n",
    "cross_val_scores_cpu = cross_val_score(pipeline, X_train, y_train, scoring=\"roc_auc\", cv=3)\n",
    "print(\"3-fold AUC: \", np.mean(cross_val_scores_cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uesu/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6090251374978501"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = pipeline.fit(X_train, y_train)\n",
    "dev = model.predict(X_test)\n",
    "roc_auc_score(dev, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uesu/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(testDF)\n",
    "Utils.submit(preds, \"firstTry_weights_gamma.csv\", \"firstTry weights gamma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Dataset | roc_auc | \n",
    "| --- | --- | \n",
    "| Training set | 0.853  |\n",
    "| Dev set | 0.609 |\n",
    "| Test set (public) |0.775060 | \n",
    "| Test set (private) | 0.769128 | \n",
    "\n",
    "### First try evaluation\n",
    "\n",
    "We are definitely overfitting the training set. \n",
    "\n",
    "There's large variance, 0.85 - 0.609 almost 0.25 difference in ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning\n",
    "\n",
    "1. Randomised Search\n",
    "2. Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 399 candidates, totalling 1197 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 160 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 410 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 760 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1197 out of 1197 | elapsed: 15.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my best score: 0.8649865004930518\n",
      "Pipeline(memory=None,\n",
      "     steps=[('featureunion', DataFrameMapper(default=False, df_out=True,\n",
      "        features=[(['RevolvingUtilizationOfUnsecuredLines'], Imputer(axis=0, copy=True, missing_values='NaN', strategy='median', verbose=0)), (['age'], Imputer(axis=0, copy=True, missing_values='NaN', strategy='median', verbose=0)),...=0, reg_lambda=1, scale_pos_weight=13.960728088766986,\n",
      "       seed=None, silent=True, subsample=1))])\n"
     ]
    }
   ],
   "source": [
    "gbm_param_grid = {\n",
    "        'clf__learning_rate': np.arange(0.05, 1, 0.05),\n",
    "        'clf__max_depth': np.arange(3, 10, 1),\n",
    "        'clf__n_estimators': np.arange(50, 200, 50)#,\n",
    "        #'clf__gamma':[5,10,20]\n",
    "}\n",
    "\n",
    "grid_roc_auc = GridSearchCV(pipeline,\n",
    "    param_grid=gbm_param_grid,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the estimator\n",
    "grid_roc_auc.fit(X_train, y_train)\n",
    "\n",
    "# Compute metrics\n",
    "print(f'my best score: {grid_roc_auc.best_score_}')\n",
    "print(grid_roc_auc.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.598183473983141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uesu/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "preds = grid_roc_auc.predict(X_test)\n",
    "print(f'AUC: {roc_auc_score(preds, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting with the gamma turned on the AUC is bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uesu/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "preds = grid_roc_auc.predict(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predsSubmit = model.predict(testDF)\n",
    "Utils.submit(preds, \"xgb_straitified_processing_weights_gamma_gridsearch2.csv\", \"xgb stratified preprocessing weights gamma grid2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=20, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=150,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=13.960728088766986,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_roc_auc.best_estimator_.named_steps['clf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=20, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=150,\n",
    "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=13.960728088766986,\n",
    "       seed=None, silent=True, subsample=1)\n",
    "```     \n",
    "With the grid search\n",
    "\n",
    "| public | private |  \n",
    "| --- | --- | \n",
    "| 0.790252 | 0.783193 | \n",
    "\n",
    "\n",
    "\n",
    "| Dataset | XGB (no tuning) | XGB (with some tuning)|  Random Forest (no tuning) |\n",
    "| --- | --- |  --- | --- |\n",
    "| Training set | 0.853  | | |\n",
    "| Dev set | 0.609 | | |\n",
    "| Test set (public) |0.775060 | 0.790252 | |\n",
    "| Test set (private) | 0.769128 | 0.783193 | |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.93316, 1: 0.06684}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, testDF = loadData(logTransform=True, \n",
    "                                                    impute=False, \n",
    "                                                    preprocessed=False)\n",
    "\n",
    "#Recalculate weights for random forest the input takes a dictionary in this case\n",
    "weights = np.array(classSep['value']/np.sum(classSep['value']))\n",
    "classweight = {1:weights[0], 0:weights[1]}\n",
    "classweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-fold AUC:  0.8445269407753803\n",
      "test AUC:  0.6090251374978501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uesu/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "   (\"featureunion\", numeric_imputation_mapper),\n",
    "   (\"rf\",RandomForestClassifier(random_state=123, n_jobs=-1, class_weight=classweight, n_estimators=400)) #tried 500 gives the same\n",
    "])\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_val_scores = cross_val_score(rf_pipeline, X_train, y_train, scoring=\"roc_auc\", cv=3)\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "    \n",
    "dev = model.predict(X_test)\n",
    "testScore = roc_auc_score(dev, y_test)\n",
    "    \n",
    "print(\"3-fold AUC: \", np.mean(cross_val_scores))\n",
    "print(\"test AUC: \", testScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uesu/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "rfPreds = model.predict(testDF)\n",
    "#nestimators 500 or 400 gets the same score\n",
    "Utils.submit(rfPreds, \"rf_400.csv\", \"rf 400\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF is doing exactly the same with XGB without tuning\n",
    "\n",
    "| Dataset | XGB (no tuning) | Random Forest (no tuning) |\n",
    "| --- | --- |  --- |\n",
    "| Training set | 0.853  | 0.44|\n",
    "| Dev set | 0.609 | 0.609 |\n",
    "| Test set (public) |0.775060 | 0.775060 |\n",
    "| Test set (private) | 0.769128 | 0.769128 |\n",
    "\n",
    "\n",
    "_VERY SIMILAR_\n",
    "\n",
    "This is probably due to the fact that both are tree based ensembles, lets include others to add abit more diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Stacking / ensembling\n",
    "\n",
    "tried stacking with a metaclassifier (linear regression) doesnt work its, worse. \n",
    "tried ensembling (vote) better but the score is still worse than individual predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test, testDF = loadData(\n",
    "    logTransform=True, \n",
    "    impute=False, \n",
    "    preprocessed=False, \n",
    "    continuous=False\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe1 = make_pipeline(numeric_imputation_mapper,\n",
    "                      XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=20, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=3, min_child_weight=1, missing=None, n_estimators=150,\n",
    "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=13.960728088766986,\n",
    "       seed=None, silent=True, subsample=1))\n",
    "\n",
    "pipe2 = make_pipeline(numeric_imputation_mapper,\n",
    "                      RandomForestClassifier(max_depth=None, random_state=123, class_weight=classweight, n_estimators=400)\n",
    "                      )\n",
    "\n",
    "\n",
    "# Initializing models\n",
    "eclf = EnsembleVoteClassifier(clfs=[pipe1, pipe2],\n",
    "                              weights=[1, 1], voting='soft')\n",
    "eclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devstack = eclf.predict(X_test)\n",
    "testScore = roc_auc_score(devstack, y_test)\n",
    "print(f'test AUC: {testScore}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "votePreds = eclf.predict(testDF)\n",
    "submit(votePreds, \"xgb_rf_voting2.csv\", \"xgb rf voting2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding RF and XGB brought the score down: private, public: \n",
    "        0.721574, 0.722799\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looked at the discussion forums for some inspiration and came across this guy which wrote 500 lines to create 80 columns, lets use that.\n",
    "\n",
    "https://www.kaggle.com/c/GiveMeSomeCredit/discussion/31514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 120000 entries, 146722 to 11328\n",
      "Data columns (total 80 columns):\n",
      "UnknownNumberOfDependents                       120000 non-null int64\n",
      "UnknownMonthlyIncome                            120000 non-null int64\n",
      "NoDependents                                    120000 non-null int64\n",
      "NoIncome                                        120000 non-null int64\n",
      "ZeroDebtRatio                                   120000 non-null int64\n",
      "UnknownIncomeDebtRatio                          120000 non-null int64\n",
      "WeirdRevolvingUtilization                       120000 non-null float64\n",
      "ZeroRevolvingUtilization                        120000 non-null int64\n",
      "Log.Debt                                        120000 non-null float64\n",
      "RevolvingLines                                  120000 non-null int64\n",
      "HasRevolvingLines                               120000 non-null int64\n",
      "HasRealEstateLoans                              120000 non-null int64\n",
      "HasMultipleRealEstateLoans                      120000 non-null int64\n",
      "EligibleSS                                      120000 non-null int64\n",
      "DTIOver33                                       120000 non-null int64\n",
      "DTIOver43                                       120000 non-null int64\n",
      "DisposableIncome                                120000 non-null float64\n",
      "RevolvingToRealEstate                           120000 non-null float64\n",
      "NumberOfTime30.59DaysPastDueNotWorseLarge       120000 non-null int64\n",
      "NumberOfTime30.59DaysPastDueNotWorse96          120000 non-null int64\n",
      "NumberOfTime30.59DaysPastDueNotWorse98          120000 non-null int64\n",
      "Never30.59DaysPastDueNotWorse                   120000 non-null int64\n",
      "NumberOfTime60.89DaysPastDueNotWorseLarge       120000 non-null int64\n",
      "NumberOfTime60.89DaysPastDueNotWorse96          120000 non-null int64\n",
      "NumberOfTime60.89DaysPastDueNotWorse98          120000 non-null int64\n",
      "Never60.89DaysPastDueNotWorse                   120000 non-null int64\n",
      "NumberOfTimes90DaysLateLarge                    120000 non-null int64\n",
      "NumberOfTimes90DaysLate96                       120000 non-null int64\n",
      "NumberOfTimes90DaysLate98                       120000 non-null int64\n",
      "Never90DaysLate                                 120000 non-null int64\n",
      "IncomeDivBy10                                   120000 non-null int64\n",
      "IncomeDivBy100                                  120000 non-null int64\n",
      "IncomeDivBy1000                                 120000 non-null int64\n",
      "IncomeDivBy5000                                 120000 non-null int64\n",
      "Weird0999Utilization                            120000 non-null int64\n",
      "FullUtilization                                 120000 non-null int64\n",
      "ExcessUtilization                               120000 non-null int64\n",
      "NumberOfTime30.89DaysPastDueNotWorse            120000 non-null int64\n",
      "Never30.89DaysPastDueNotWorse                   120000 non-null int64\n",
      "NeverPastDue                                    120000 non-null int64\n",
      "Log.RevolvingUtilizationTimesLines              120000 non-null float64\n",
      "Log.RevolvingUtilizationOfUnsecuredLines        120000 non-null float64\n",
      "DelinquenciesPerLine                            120000 non-null float64\n",
      "MajorDelinquenciesPerLine                       120000 non-null float64\n",
      "MinorDelinquenciesPerLine                       120000 non-null float64\n",
      "DelinquenciesPerRevolvingLine                   120000 non-null float64\n",
      "MajorDelinquenciesPerRevolvingLine              120000 non-null float64\n",
      "MinorDelinquenciesPerRevolvingLine              120000 non-null float64\n",
      "Log.DebtPerLine                                 120000 non-null float64\n",
      "Log.DebtPerRealEstateLine                       120000 non-null float64\n",
      "Log.DebtPerPerson                               120000 non-null float64\n",
      "RevolvingLinesPerPerson                         120000 non-null float64\n",
      "RealEstateLoansPerPerson                        120000 non-null float64\n",
      "YearsOfAgePerDependent                          120000 non-null float64\n",
      "Log.MonthlyIncome                               120000 non-null float64\n",
      "Log.IncomePerPerson                             120000 non-null float64\n",
      "Log.IncomeAge                                   120000 non-null float64\n",
      "Log.NumberOfTimesPastDue                        120000 non-null float64\n",
      "Log.NumberOfTimes90DaysLate                     120000 non-null float64\n",
      "Log.NumberOfTime30.59DaysPastDueNotWorse        120000 non-null float64\n",
      "Log.NumberOfTime60.89DaysPastDueNotWorse        120000 non-null float64\n",
      "Log.Ratio90to30.59DaysLate                      120000 non-null float64\n",
      "Log.Ratio90to60.89DaysLate                      120000 non-null float64\n",
      "AnyOpenCreditLinesOrLoans                       120000 non-null int64\n",
      "Log.NumberOfOpenCreditLinesAndLoans             120000 non-null float64\n",
      "Log.NumberOfOpenCreditLinesAndLoansPerPerson    120000 non-null float64\n",
      "Has.Dependents                                  120000 non-null int64\n",
      "Log.HouseholdSize                               120000 non-null float64\n",
      "Log.DebtRatio                                   120000 non-null float64\n",
      "Log.DebtPerDelinquency                          120000 non-null float64\n",
      "Log.DebtPer90DaysLate                           120000 non-null float64\n",
      "Log.UnknownIncomeDebtRatio                      120000 non-null float64\n",
      "Log.UnknownIncomeDebtRatioPerPerson             120000 non-null float64\n",
      "Log.UnknownIncomeDebtRatioPerLine               120000 non-null float64\n",
      "Log.UnknownIncomeDebtRatioPerRealEstateLine     120000 non-null float64\n",
      "Log.UnknownIncomeDebtRatioPerDelinquency        120000 non-null float64\n",
      "Log.UnknownIncomeDebtRatioPer90DaysLate         120000 non-null float64\n",
      "Log.NumberRealEstateLoansOrLines                120000 non-null float64\n",
      "LowAge                                          120000 non-null int64\n",
      "Log.age                                         120000 non-null float64\n",
      "dtypes: float64(41), int64(39)\n",
      "memory usage: 74.2 MB\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, testDF = loadData(logTransform=False, \n",
    "                                                    impute=False, \n",
    "                                                    preprocessed=True)\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uesu/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "'min_child_weight': 10.0,\n",
    "'objective': 'binary:logistic',\n",
    "'max_depth': 5,\n",
    "'eval_metric': 'auc',\n",
    "'max_delta_step': 1.8,\n",
    "'colsample_bytree': 0.4,\n",
    "'subsample': 0.8,\n",
    "'eta': 0.025,\n",
    "'gamma': 0.65,\n",
    "'num_boost_round' : 391\n",
    "}\n",
    "tuned = xgb.XGBClassifier( **params, scale_pos_weight=weights)\n",
    "tuned.fit(X_train, y_train)\n",
    "preds = tuned.predict(testDF)\n",
    "Utils.submit(preds, \"discusssion2.csv\", \"discussionSuperParameters2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BS\n",
    "\n",
    "Without weights\n",
    "\n",
    "| Public | Private | \n",
    "| --- | --- | \n",
    "| 0.599727 | 0.593717 | \n",
    "\n",
    "With weights\n",
    "\n",
    "| Public | Private | \n",
    "| --- | --- | \n",
    "| 0.791425 | 0.782578 | \n",
    "\n",
    "Which is comparable with my own tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 120000 entries, 146722 to 11328\n",
      "Data columns (total 16 columns):\n",
      "RevolvingUtilizationOfUnsecuredLines        120000 non-null float64\n",
      "age                                         120000 non-null int64\n",
      "NumberOfTime30-59DaysPastDueNotWorse        120000 non-null int64\n",
      "DebtRatio                                   120000 non-null float64\n",
      "MonthlyIncome                               120000 non-null float64\n",
      "NumberOfOpenCreditLinesAndLoans             120000 non-null int64\n",
      "NumberOfTimes90DaysLate                     120000 non-null int64\n",
      "NumberRealEstateLoansOrLines                120000 non-null int64\n",
      "NumberOfTime60-89DaysPastDueNotWorse        120000 non-null int64\n",
      "NumberOfDependents                          120000 non-null float64\n",
      "NumberOfTime30-59DaysPastDueNotWorse-log    120000 non-null float64\n",
      "MonthlyIncome-log                           120000 non-null float64\n",
      "NumberOfOpenCreditLinesAndLoans-log         120000 non-null float64\n",
      "NumberOfTimes90DaysLate-log                 120000 non-null float64\n",
      "NumberRealEstateLoansOrLines-log            120000 non-null float64\n",
      "NumberOfTime60-89DaysPastDueNotWorse-log    120000 non-null float64\n",
      "dtypes: float64(10), int64(6)\n",
      "memory usage: 15.6 MB\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test, testDF = Utils.loadData(logTransform=True, \n",
    "                                                    impute=True, \n",
    "                                                    preprocessed=False)\n",
    "X_train.info()\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras import regularizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import BatchNormalization\n",
    "#import tensorflow as tf\n",
    "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.98037042e-01,  5.60000000e+01,  1.00000000e+00,  6.05718590e-02,\n",
       "         5.31500000e+03,  9.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  4.34294477e-09,  3.72550327e+00,\n",
       "         9.54242510e-01, -8.00000000e+00, -8.00000000e+00, -8.00000000e+00]),\n",
       " (120000, 16))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "\n",
    "# split into input (X) and output (Y) variables\n",
    "X_train_matrix = X_train.as_matrix(columns=[X_train.columns[:]])\n",
    "X_train_matrix[0,:], X_train_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_matrix = X_test.as_matrix(columns=[X_test.columns[:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5358147509800945, 1: 7.480364044383493}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "class_weight\n",
    "class_weight_dict = dict(enumerate(class_weight))\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uesu/anaconda3/lib/python3.6/site-packages/sklearn/base.py:115: DeprecationWarning: Estimator KerasClassifier modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/home/uesu/anaconda3/lib/python3.6/site-packages/sklearn/base.py:115: DeprecationWarning: Estimator KerasClassifier modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/home/uesu/anaconda3/lib/python3.6/site-packages/sklearn/base.py:115: DeprecationWarning: Estimator KerasClassifier modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/home/uesu/anaconda3/lib/python3.6/site-packages/sklearn/base.py:115: DeprecationWarning: Estimator KerasClassifier modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/home/uesu/anaconda3/lib/python3.6/site-packages/sklearn/base.py:115: DeprecationWarning: Estimator KerasClassifier modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=16, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=2000, verbose=0, class_weight=class_weight_dict)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "results = cross_val_score(estimator, X_train_matrix, y_train.values, cv=kfold, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(\"Accuracy Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is a bad metric cause of the class imbalance, if i miss the delinquency class I'll still get very high accuracy. \n",
    "\n",
    "However KERAS doesnt come naturally with its own `ROC_AUC` scoring.\n",
    "So I'm going to hack this by using sklearn's randomseSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uesu/anaconda3/lib/python3.6/site-packages/sklearn/base.py:115: DeprecationWarning: Estimator KerasClassifier modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/home/uesu/anaconda3/lib/python3.6/site-packages/sklearn/base.py:115: DeprecationWarning: Estimator KerasClassifier modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/home/uesu/anaconda3/lib/python3.6/site-packages/sklearn/base.py:115: DeprecationWarning: Estimator KerasClassifier modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/home/uesu/anaconda3/lib/python3.6/site-packages/sklearn/base.py:115: DeprecationWarning: Estimator KerasClassifier modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  2.1min finished\n",
      "/home/uesu/anaconda3/lib/python3.6/site-packages/sklearn/base.py:115: DeprecationWarning: Estimator KerasClassifier modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my best score: 0.8148518186067275\n",
      "<keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd2e349d860>\n"
     ]
    }
   ],
   "source": [
    "param_grid = {}\n",
    "random_search = RandomizedSearchCV(estimator, \n",
    "    param_distributions=param_grid, verbose=1, n_iter=1, scoring=\"roc_auc\")\n",
    "random_search.fit(X_train_matrix, y_train)\n",
    "print(f'my best score: {random_search.best_score_}')\n",
    "print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dev set AUC is 0.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test AUC:  0.6018857975090398\n"
     ]
    }
   ],
   "source": [
    "#estimator.fit(X_train_matrix, y_train.values)\n",
    "preds = estimator.predict(X_test_matrix)\n",
    "testScore = roc_auc_score(preds, y_test)\n",
    "print(\"test AUC: \", testScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testDF_matrix = testDF.as_matrix(columns=[X_test.columns[:]])\n",
    "preds = estimator.predict(testDF_matrix)\n",
    "Utils.submit(preds.flatten(), \"singleLayer.csv\", \"single Layer with weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Severely overfitting, time to do some feature engineering and ensembling\n",
    "\n",
    "# Multilayer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_fn(nr_of_layers = 2,\n",
    "             first_layer_size = 10,\n",
    "             layers_slope_coeff = 0.8,\n",
    "             dropout = 0.5,\n",
    "             activation = \"relu\",\n",
    "             weight_l2 = 0.01,\n",
    "             act_l2 = 0.01,\n",
    "             input_dim = 16):\n",
    "\n",
    "    result_model = Sequential()\n",
    "    result_model.add(Dense(first_layer_size,\n",
    "                           input_dim = input_dim,\n",
    "                           activation=activation,\n",
    "                           W_regularizer= l2(weight_l2),\n",
    "                           activity_regularizer=l2(act_l2)\n",
    "                           ))\n",
    "\n",
    "    current_layer_size = int(first_layer_size * layers_slope_coeff) + 1\n",
    "\n",
    "    for index_of_layer in range(nr_of_layers - 1):\n",
    "\n",
    "        result_model.add(BatchNormalization())\n",
    "        result_model.add(Dropout(dropout))\n",
    "        result_model.add(Dense(current_layer_size,\n",
    "                               W_regularizer= l2(weight_l2),\n",
    "                               activation=activation,\n",
    "                               activity_regularizer=l2(act_l2)\n",
    "                               ))\n",
    "\n",
    "        current_layer_size = int(current_layer_size * layers_slope_coeff) + 1\n",
    "\n",
    "    result_model.add(Dense(1,\n",
    "                           activation = \"sigmoid\",\n",
    "                           W_regularizer = l2(weight_l2)))\n",
    "\n",
    "    result_model.compile(optimizer=\"adam\", metrics = [\"accuracy\"], loss = \"binary_crossentropy\")\n",
    "\n",
    "    return result_model\n",
    "\n",
    "NeuralNet = KerasClassifier(build_fn, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5358147509800945, 1: 7.480364044383493}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uesu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, input_dim=16, activation=\"relu\", activity_regularizer=<keras.reg..., kernel_regularizer=<keras.reg...)`\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/uesu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(7, activation=\"relu\", activity_regularizer=<keras.reg..., kernel_regularizer=<keras.reg...)`\n",
      "/home/uesu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, activation=\"relu\", activity_regularizer=<keras.reg..., kernel_regularizer=<keras.reg...)`\n",
      "/home/uesu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "#copied from https://stackoverflow.com/questions/37523882/keras-wrappers-for-scikit-learn-auc-scorer-is-not-working\n",
    "param_grid = {\n",
    "    \"nr_of_layers\" : [2, 3, 4, 5],\n",
    "    \"first_layer_size\" : [5, 10, 15],\n",
    "    \"layers_slope_coeff\" : [0.4, 0.6, 0.8],\n",
    "    \"dropout\" : [0.3, 0.5, 0.8],\n",
    "    \"weight_l2\" : [0.01, 0.001, 0.0001],\n",
    "    \"batch_size\" : [2000],\n",
    "    \"epochs\" : [10]\n",
    "}\n",
    "with tf.device('/gpu:0'):\n",
    "    random_search = RandomizedSearchCV(NeuralNet, \n",
    "        param_distributions=param_grid, verbose=0, n_iter=10, scoring=\"roc_auc\", )\n",
    "    random_search.fit(X_train_matrix, y_train.values,class_weight=class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my best score: 0.49976794983787887\n"
     ]
    }
   ],
   "source": [
    "print(f'my best score: {random_search.best_score_}')\n",
    "#print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "#def create_model():\n",
    "    # create model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(16,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Dense(256, activation='relu', activity_regularizer=regularizers.l1(10e-5)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "#model.add(Dense(32, activation='relu', activity_regularizer=regularizers.l1(10e-5)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='sigmoid')) #output\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "nb_epoch = 100\n",
    "batch_size = 2000\n",
    "\n",
    "#def train_and_evaluate__model(model, data, label, data_test, label_test):\n",
    "\n",
    "model.fit(\n",
    "        X_train_matrix, y_train.values, validation_split=0.1, \n",
    "        #callbacks=[early_stopping],\n",
    "        class_weight=[0.5, 100], \n",
    "        epochs = nb_epoch,\n",
    "        batch_size = batch_size\n",
    ")\n",
    "# skf = StratifiedKFold(y_train, n_folds=10, shuffle=True)\n",
    "# for i, (train, test) in enumerate(skf):\n",
    "#     print \"Running Fold\", i+1, \"/\", n_folds\n",
    "#     model = None # Clearing the NN.\n",
    "#     model = create_model()\n",
    "#     train_and_evaluate_model(model, X_train[train], y_train[train], X_test[test], y_test[test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_matrix.shape, np.sum(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_matrix = X_test.as_matrix(columns=[X_test.columns[:]])\n",
    "preds = model.predict(X_train_matrix)\n",
    "preds\n",
    "#fail the neural net still thinks everyone is 0\n",
    "#accuracy = float(np.sum(preds.flatten() == y_test)/y_test.shape[0])\n",
    "#accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder (Doesn't work)\n",
    "\n",
    "(didnt work the loss is incredulous)\n",
    "this is based from the inspiration i got from this post by Veneline Valkov\n",
    "\n",
    "https://medium.com/@curiousily/credit-card-fraud-detection-using-autoencoders-in-keras-tensorflow-for-hackers-part-vii-20e0c85301bd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, testDF = loadData(logTransform=False, \n",
    "                                                    impute=False, \n",
    "                                                    preprocessed=True, continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R -i X_train \n",
    "\n",
    "suppressWarnings({ \n",
    "        library(tidyverse)\n",
    "        library(GGally)\n",
    "        X_train %>% #select(-DebtRatio, -NumberOfTime30.59DaysPastDueNotWorse, -MonthlyIncome, \n",
    "#                                    -NumberOfOpenCreditLinesAndLoans, -NumberOfTimes90DaysLate, \n",
    "#                                    -NumberRealEstateLoansOrLines, -NumberOfTime60.89DaysPastDueNotWorse) %>% \n",
    "        ggpairs() %>%\n",
    "        ggsave(filename=\"ggpairs_selected.png\", w=30, h=30, dpi=300) \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./ggpairs_selected.png\">\n",
    "<caption><center> **Figure 3**: Pairs plot</center></caption><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "defaulting = X_train[y_train == 1]\n",
    "normal = X_train[y_train == 0]\n",
    "normal_test = X_test[y_test == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normal = normal.values\n",
    "normal_test = normal_test.values\n",
    "normal_test.shape, normal.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 18 \n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", \n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
    "\n",
    "decoder = Dense(int(encoding_dim / 2), activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "\n",
    "autoencoder = Model(input=input_layer, output=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "nb_epoch = 100\n",
    "batch_size = 1000\n",
    "\n",
    "autoencoder.compile(optimizer='adam', \n",
    "                    loss='mean_squared_error', \n",
    "                    metrics=['accuracy'])\n",
    "autoencoder.summary()\n",
    "checkpointer = ModelCheckpoint(filepath=\"model2.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir='./logs',\n",
    "                          histogram_freq=0,\n",
    "                          write_graph=True,\n",
    "                          write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = autoencoder.fit(normal, normal,\n",
    "                    nb_epoch=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(normal_test, normal_test),\n",
    "                    verbose=1,\n",
    "                    callbacks=[tensorboard, checkpointer]).history\n",
    "\n",
    "#gave up the loss is too fucking big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right');"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
